
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryptocurrency Arbitrage Prediction Model\n",
    "\n",
    "This notebook demonstrates how to build a model to predict arbitrage opportunities between cryptocurrency exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to MongoDB to retrieve historical price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mock data since we don't have real data\n",
    "print(\"Creating mock data for demonstration.\")\n",
    "    \n",
    "# Create mock data\n",
    "mock_data = []\n",
    "base_price = 60000\n",
    "timestamp = datetime.now() - timedelta(days=30)\n",
    "exchanges = ['binance', 'kucoin', 'bybit', 'okx']\n",
    "\n",
    "for day in range(30):\n",
    "    daily_timestamp = timestamp + timedelta(days=day)\n",
    "    for hour in range(24):\n",
    "        hourly_timestamp = daily_timestamp + timedelta(hours=hour)\n",
    "        for exchange in exchanges:\n",
    "            # Add some random variation to price\n",
    "            price = base_price * (1 + np.random.normal(0, 0.01))\n",
    "            volume = np.random.randint(10000, 100000)\n",
    "            \n",
    "            mock_data.append({\n",
    "                'timestamp': hourly_timestamp,\n",
    "                'symbol': 'BTC/USDT',\n",
    "                'exchange': exchange,\n",
    "                'price': price,\n",
    "                'volume': volume\n",
    "            })\n",
    "            \n",
    "        # Slightly adjust base price for next hour\n",
    "        base_price = base_price * (1 + np.random.normal(0, 0.001))\n",
    "        \n",
    "df = pd.DataFrame(mock_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(f\"Shape of the dataset: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values if needed\n",
    "df = df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table with exchanges as columns and timestamp as index\n",
    "pivot_df = df.pivot_table(index='timestamp', columns='exchange', values='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize price differences between exchanges\n",
    "plt.figure(figsize=(14, 7))\n",
    "for exchange in pivot_df.columns:\n",
    "    plt.plot(pivot_df.index, pivot_df[exchange], label=exchange)\n",
    "plt.title('BTC/USDT Price by Exchange')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Price (USDT)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Arbitrage Opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate price differences between exchanges\n",
    "exchanges = pivot_df.columns\n",
    "arbitrage_df = pd.DataFrame(index=pivot_df.index)\n",
    "\n",
    "for i in range(len(exchanges)):\n",
    "    for j in range(i+1, len(exchanges)):\n",
    "        exchange1 = exchanges[i]\n",
    "        exchange2 = exchanges[j]\n",
    "        \n",
    "        # Calculate percentage difference\n",
    "        diff_col = f\"{exchange1}_vs_{exchange2}\"\n",
    "        arbitrage_df[diff_col] = ((pivot_df[exchange2] - pivot_df[exchange1]) / pivot_df[exchange1]) * 100\n",
    "\n",
    "# Display the arbitrage opportunities\n",
    "arbitrage_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize arbitrage opportunities over time\n",
    "plt.figure(figsize=(14, 7))\n",
    "for col in arbitrage_df.columns:\n",
    "    plt.plot(arbitrage_df.index, arbitrage_df[col], label=col)\n",
    "plt.title('Arbitrage Opportunities Over Time')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Price Difference (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data to hourly intervals for consistency\n",
    "hourly_df = arbitrage_df.resample('1H').mean().fillna(method='ffill')\n",
    "\n",
    "# Create features for time of day, day of week, etc.\n",
    "hourly_df['hour'] = hourly_df.index.hour\n",
    "hourly_df['day_of_week'] = hourly_df.index.dayofweek\n",
    "hourly_df['day_of_month'] = hourly_df.index.day\n",
    "\n",
    "# Create lag features\n",
    "for col in arbitrage_df.columns:\n",
    "    for lag in [1, 3, 6, 12, 24]:\n",
    "        hourly_df[f\"{col}_lag_{lag}\"] = hourly_df[col].shift(lag)\n",
    "        \n",
    "# Create rolling statistics\n",
    "for col in arbitrage_df.columns:\n",
    "    for window in [6, 12, 24]:\n",
    "        hourly_df[f\"{col}_mean_{window}\"] = hourly_df[col].rolling(window=window).mean()\n",
    "        hourly_df[f\"{col}_std_{window}\"] = hourly_df[col].rolling(window=window).std()\n",
    "        hourly_df[f\"{col}_max_{window}\"] = hourly_df[col].rolling(window=window).max()\n",
    "        hourly_df[f\"{col}_min_{window}\"] = hourly_df[col].rolling(window=window).min()\n",
    "\n",
    "# Drop rows with NaN values\n",
    "hourly_df = hourly_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one arbitrage pair to predict\n",
    "target_col = arbitrage_df.columns[0]  # e.g., 'binance_vs_kucoin'\n",
    "\n",
    "# Prepare data for modeling\n",
    "X = hourly_df.drop(arbitrage_df.columns, axis=1)\n",
    "y = hourly_df[target_col]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
    "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Random Forest - MSE: {mean_squared_error(y_test, y_pred_rf)}\")\n",
    "print(f\"Random Forest - MAE: {mean_absolute_error(y_test, y_pred_rf)}\")\n",
    "print(f\"Random Forest - R²: {r2_score(y_test, y_pred_rf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gradient Boosting model\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Gradient Boosting - MSE: {mean_squared_error(y_test, y_pred_gb)}\")\n",
    "print(f\"Gradient Boosting - MAE: {mean_absolute_error(y_test, y_pred_gb)}\")\n",
    "print(f\"Gradient Boosting - R²: {r2_score(y_test, y_pred_gb)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize and Interpret Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test.index, y_test.values, label='Actual')\n",
    "plt.plot(y_test.index, y_pred_rf, label='Random Forest')\n",
    "plt.plot(y_test.index, y_pred_gb, label='Gradient Boosting')\n",
    "plt.title(f'Actual vs Predicted Arbitrage Opportunities - {target_col}')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Arbitrage Difference (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance_rf': rf_model.feature_importances_,\n",
    "    'importance_gb': gb_model.feature_importances_\n",
    "}).sort_values('importance_rf', ascending=False)\n",
    "\n",
    "# Plot top 15 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='importance_rf', y='feature', data=feature_importances.head(15))\n",
    "plt.title('Top 15 Feature Importances - Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and scaler\n",
    "if r2_score(y_test, y_pred_rf) > r2_score(y_test, y_pred_gb):\n",
    "    best_model = rf_model\n",
    "    print(\"Saving Random Forest model\")\n",
    "else:\n",
    "    best_model = gb_model\n",
    "    print(\"Saving Gradient Boosting model\")\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Save model and scaler\n",
    "model_filename = f\"models/arbitrage_model_{target_col.replace('/', '_')}.pkl\"\n",
    "scaler_filename = f\"models/arbitrage_scaler_{target_col.replace('/', '_')}.pkl\"\n",
    "\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "    \n",
    "with open(scaler_filename, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "    \n",
    "print(f\"Model saved to {model_filename}\")\n",
    "print(f\"Scaler saved to {scaler_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Make Future Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature data for next 24 hours\n",
    "last_time = hourly_df.index[-1]\n",
    "future_times = [last_time + timedelta(hours=i+1) for i in range(24)]\n",
    "future_df = pd.DataFrame(index=future_times)\n",
    "\n",
    "# Add time-based features\n",
    "future_df['hour'] = future_df.index.hour\n",
    "future_df['day_of_week'] = future_df.index.dayofweek\n",
    "future_df['day_of_month'] = future_df.index.day\n",
    "\n",
    "# Initialize with last known values\n",
    "for col in hourly_df.columns:\n",
    "    if col not in ['hour', 'day_of_week', 'day_of_month']:\n",
    "        future_df[col] = hourly_df[col].iloc[-1]\n",
    "\n",
    "# Scale future data\n",
    "future_features = future_df[X.columns]\n",
    "future_scaled = scaler.transform(future_features)\n",
    "\n",
    "# Make predictions\n",
    "future_predictions = best_model.predict(future_scaled)\n",
    "\n",
    "# Add predictions to the future DataFrame\n",
    "future_df['prediction'] = future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(hourly_df.index[-48:], hourly_df[target_col][-48:], label='Historical')\n",
    "plt.plot(future_df.index, future_df['prediction'], label='Predicted', linestyle='--')\n",
    "plt.axvline(x=last_time, color='r', linestyle='-', alpha=0.3, label='Now')\n",
    "plt.title(f'Predicted Arbitrage Opportunities - {target_col}')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Arbitrage Difference (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Identify Optimal Trading Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold for profitable arbitrage (accounting for fees)\n",
    "threshold = 0.5  # 0.5% profit after fees\n",
    "\n",
    "# Identify predicted opportunities above threshold\n",
    "profitable_times = future_df[future_df['prediction'] > threshold]\n",
    "\n",
    "print(f\"Predicted profitable arbitrage opportunities for {target_col}:\")\n",
    "if len(profitable_times) > 0:\n",
    "    for idx, row in profitable_times.iterrows():\n",
    "        print(f\"Time: {idx}, Expected Profit: {row['prediction']:.3f}%\")\n",
    "else:\n",
    "    print(\"No profitable opportunities predicted in the next 24 hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Trading Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtesting function\n",
    "def backtest_strategy(df, target_column, threshold=0.5, investment=1000, fee_rate=0.001):\n",
    "    results = {\n",
    "        'trades': [],\n",
    "        'total_profit': 0,\n",
    "        'win_rate': 0,\n",
    "        'avg_profit': 0\n",
    "    }\n",
    "    \n",
    "    # Find opportunities\n",
    "    opportunities = df[df[target_column] > threshold]\n",
    "    \n",
    "    successful_trades = 0\n",
    "    total_profit_pct = 0\n",
    "    \n",
    "    for idx, row in opportunities.iterrows():\n",
    "        # Calculate expected profit\n",
    "        expected_profit_pct = row[target_column]\n",
    "        \n",
    "        # Calculate actual profit (considering fees)\n",
    "        actual_profit_pct = expected_profit_pct - (fee_rate * 200)  # 2 trades (buy and sell)\n",
    "        profit_amount = investment * (actual_profit_pct / 100)\n",
    "        \n",
    "        # Log trade\n",
    "        trade = {\n",
    "            'timestamp': idx,\n",
    "            'expected_profit_pct': expected_profit_pct,\n",
    "            'actual_profit_pct': actual_profit_pct,\n",
    "            'profit_amount': profit_amount,\n",
    "            'successful': actual_profit_pct > 0\n",
    "        }\n",
    "        \n",
    "        results['trades'].append(trade)\n",
    "        results['total_profit'] += profit_amount\n",
    "        \n",
    "        if actual_profit_pct > 0:\n",
    "            successful_trades += 1\n",
    "            total_profit_pct += actual_profit_pct\n",
    "    \n",
    "    # Calculate statistics\n",
    "    num_trades = len(results['trades'])\n",
    "    if num_trades > 0:\n",
    "        results['win_rate'] = successful_trades / num_trades * 100\n",
    "        results['avg_profit'] = total_profit_pct / num_trades if successful_trades > 0 else 0\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run backtest on historical data\n",
    "backtest_results = backtest_strategy(hourly_df, target_col, threshold=0.5)\n",
    "\n",
    "# Print results\n",
    "print(f\"Backtest Results for {target_col}:\")\n",
    "print(f\"Number of trades: {len(backtest_results['trades'])}\")\n",
    "print(f\"Total profit: ${backtest_results['total_profit']:.2f}\")\n",
    "print(f\"Win rate: {backtest_results['win_rate']:.2f}%\")\n",
    "print(f\"Average profit per successful trade: {backtest_results['avg_profit']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Findings\n",
    "- We've built a model to predict arbitrage opportunities between cryptocurrency exchanges\n",
    "- The model achieved reasonable accuracy in predicting price differences\n",
    "- Backtesting showed profitable trading opportunities\n",
    "\n",
    "### Next Steps\n",
    "1. Expand the model to more trading pairs\n",
    "2. Implement real-time prediction pipeline\n",
    "3. Add liquidity analysis to ensure trades can be executed\n",
    "4. Develop automated trading execution system\n",
    "5. Add risk management and position sizing logic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
